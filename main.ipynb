{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Social Distancing and Mask Detectiong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries:\n",
    "\n",
    "import cv2 \n",
    "import numpy as np \n",
    "import face_detection \n",
    "from keras.models import load_model\n",
    "from focal_loss import BinaryFocalLoss\n",
    "from scipy.spatial import distance as dist\n",
    "from keras.applications.resnet import preprocess_input as pre_resnet\n",
    "from keras.applications.mobilenet import preprocess_input as pre_mobile\n",
    "\n",
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Check for GPU:\n",
    "\n",
    "import tensorflow as tf \n",
    "x = tf.config.list_physical_devices('GPU') \n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CNN models and COCO names:\n",
    "\n",
    "#detector_cv2 = cv2.CascadeClassifier('./others/haarcascade_frontalface_default.xml')     # was just used for testing purposes, didn't yield good results here.\n",
    "\n",
    "mask_classifier_resnet = load_model('./model/resnet.h5')\n",
    "mask_classifier_mobile = load_model('./model/mobilenet.h5')\n",
    "model = YOLO(\"../project/yolov8/yolov8n.pt\")\n",
    "\n",
    "classesFile = \"./others/coco.names\"\n",
    "classes = None\n",
    "with open(classesFile, 'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main program:\n",
    "\n",
    "detector = face_detection.build_detector(\"DSFDDetector\", confidence_threshold=.7, nms_iou_threshold=.5) \n",
    "cap = cv2.VideoCapture(\"./media/testvid.mp4\")\n",
    "\n",
    "# Initialize Output Video Stream\n",
    "\n",
    "video_fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "video_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "video_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "video_n_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "out_stream = cv2.VideoWriter(\n",
    "    \"./media/video_processed.mp4\", \n",
    "    cv2.VideoWriter_fourcc('X','V','I','D'),\n",
    "    video_fps,\n",
    "    (video_width,video_height))\n",
    "\n",
    "input_width = 640\n",
    "input_height = 640\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while cap.isOpened():       \n",
    "\n",
    "    ret,img = cap.read()\n",
    "    if img is None:\n",
    "        break\n",
    "\n",
    "    img2 = img.copy()\n",
    "\n",
    "    cv2.putText(img2,  \"CV Project by Slavka\", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "    # Some Lists to work with, which will be reseted at every frame:    \n",
    "    violate=[]\n",
    "    violate1=[]\n",
    "    centroids = []\n",
    "    coordinates_people = [[(),(),]]\n",
    "    people_too_close = []\n",
    "    bounding_boxes = []\n",
    "    # Using YOLOv8 for predicting people:\n",
    "    results = model.predict(img)\n",
    "    result = results[0]\n",
    "    not_violate = []\n",
    "\n",
    "    # Append coordinates of detected people only:\n",
    "    for box in result.boxes:\n",
    "        class_id = box.cls[0].item()\n",
    "        conf = round(box.conf[0].item(), 2)\n",
    "        x0, y0, x1, y1 = [round(i) for i in box.xyxy[0].tolist()]\n",
    "        \n",
    "        if conf >= 0.4 and class_id == 0:\n",
    "            bounding_boxes.append([x0, y0, x1, y1])\n",
    "            #height = int((y1 - y0))\n",
    "            width = int((x1-x0))\n",
    "            safe_distance = int((3.055 * width * 2)/ 1.59)\n",
    "            coordinates_people.append([ (x0, y0) ,   (x1, y1) ,   safe_distance   ])\n",
    "\n",
    "            center_x = int((x0+x1) / 2)\n",
    "            center_y = int((y0+y1) / 2)\n",
    "            centroids.append((center_x, center_y))\n",
    "\n",
    "    coordinates_people.pop(0)\n",
    "\n",
    "    # If minimum 2 persons are detected in the frame: check if distance is okay, if not, add the persons to list people_too_close:\n",
    "    if len(coordinates_people) >= 2:\n",
    "        real_distance = dist.cdist(centroids, centroids, metric=\"euclidean\")\n",
    "\n",
    "        for i in range(len(coordinates_people)):\n",
    "            for j in range (i+1,len(coordinates_people)):\n",
    "                if real_distance[i,j] < coordinates_people[i][2] or real_distance[i,j] < coordinates_people[j][2]:\n",
    "                    #                                                                                                                 (x0, y0)              (x1, y1)        \n",
    "                    if [coordinates_people[i][0],coordinates_people[i][1]] not in people_too_close: people_too_close.append([coordinates_people[i][0], coordinates_people[i][1]])   \n",
    "                    if [coordinates_people[j][0],coordinates_people[j][1]] not in people_too_close: people_too_close.append([coordinates_people[j][0], coordinates_people[j][1]])\n",
    "\n",
    "\n",
    "        # Detect faces only in recognized people, which are too close to each other:\n",
    "        for idx in range(len(people_too_close)):\n",
    "            person_rgb = img[people_too_close[idx][0][1]:people_too_close[idx][1][1], people_too_close[idx][0][0]:people_too_close[idx][1][0]]\n",
    "            \n",
    "            # Draw Rectangle for testing purpose:\n",
    "            cv2.rectangle(img2, people_too_close[idx][0], people_too_close[idx][1], (0,255,255), 1)\n",
    "            person_rgb = cv2.GaussianBlur(person_rgb, (5,5), cv2.BORDER_DEFAULT) \n",
    "\n",
    "            detections = detector.detect(person_rgb)\n",
    "            test_area = 0\n",
    "            biggest_face = ((0,0),(0,0))\n",
    "            faces=[]\n",
    "            face_test = []\n",
    "\n",
    "            for i in range(len(detections)):\n",
    "                detection = np.array(detections[i])                     \n",
    "                detection = np.where(detection<0,0,detection)        \n",
    "                face_x0 = people_too_close[idx][0][0] + int(detection[0])    \n",
    "                face_x1 = people_too_close[idx][0][0] + int(detection[2])\n",
    "                face_y0 = people_too_close[idx][0][1] + int(detection[1])\n",
    "                face_y1 = people_too_close[idx][0][1] + int(detection[3])\n",
    "\n",
    "                face_area = int((face_x0 - face_x1) * (face_y0 - face_y1))\n",
    "                faces.append([ (face_x0, face_y0), (face_x1, face_y1), face_area])\n",
    "\n",
    "                # Draw Rectangle for testing purpose:\n",
    "                cv2.rectangle(img, faces[i][0], faces[i][1], (55,0,255), 1)\n",
    "                \n",
    "            for j in range(len(faces)):\n",
    "                if faces[j][2] > test_area:\n",
    "                    #              x0,y0        x1,y1          area\n",
    "                    biggest_face=(faces[j][0], faces[j][1])\n",
    "                    test_area = faces[j][2]\n",
    "\n",
    "\n",
    "            face_test.append(biggest_face)\n",
    "\n",
    "            for var in range(len(face_test)):\n",
    "                try:\n",
    "\n",
    "                    # # Draw Rectangle for testing purpose:\n",
    "                    cv2.rectangle(img2, (face_test[var][0]), (face_test[var][1]), (255,255,0), 1)\n",
    "\n",
    "\n",
    "        # ############################################ RESNET #############################################\n",
    "                    face_rgb = img[face_test[var][0][1]:face_test[var][1][1], face_test[var][0][0]:face_test[var][1][0],::-1]\n",
    "                    face_arr = cv2.resize(face_rgb, (224, 224), interpolation=cv2.INTER_NEAREST)   \n",
    "                    face_arr = pre_resnet(face_arr)      \n",
    "                    face_arr = cv2.GaussianBlur(face_arr, (9,9), cv2.BORDER_DEFAULT)    \n",
    "                    face_arr = np.expand_dims(face_arr, axis=0)           \n",
    "                    \n",
    "                    check_if_mask = mask_classifier_resnet.predict(face_arr)\n",
    "        # ############################################# RESNET #############################################\n",
    "\n",
    "        ############################################ MobileNet #############################################\n",
    "\n",
    "                    # face_rgb = img[face_test[var][0][1]:face_test[var][1][1], face_test[var][0][0]:face_test[var][1][0],::-1]\n",
    "                    # face_arr = cv2.resize(face_rgb, (224, 224), interpolation=cv2.INTER_NEAREST)    \n",
    "                    # face_arr = pre_mobile(face_arr)   \n",
    "                    # face_arr = cv2.GaussianBlur(face_arr, (5,5), cv2.BORDER_DEFAULT)\n",
    "                    # face_arr = np.expand_dims(face_arr, axis=0)           \n",
    "                        \n",
    "                    # check_if_mask = mask_classifier_mobile.predict(face_arr)\n",
    "\n",
    "        ############################################ MobileNet #############################################\n",
    "\n",
    "                    if check_if_mask[0][0] > 0.89:\n",
    "                        violate.append(people_too_close[idx])\n",
    "                        # Draw Circle for testing purpose:\n",
    "                        cv2.circle(img2, face_test[var][0], 3, (0, 255,0),2)\n",
    "\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    # Draw red bounding box if violating the rules:\n",
    "    for m in range(len(violate)):\n",
    "        cv2.rectangle(img2, violate[m][0], violate[m][1], (0,0,255), 2)     \n",
    "\n",
    "    if ret:\n",
    "        out_stream.write(img2)\n",
    "\n",
    "    cv2.imshow(\"Video\", img2)\n",
    "\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()    \n",
    "out_stream.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
